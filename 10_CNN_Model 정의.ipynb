{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1-HdRR266M6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Conv2d(in_channels=4, #입력데이타의 channel수\n",
    "                  out_channels=2, #filter수\n",
    "                  kernel_size=3, #filter의 크기\n",
    "                 )\n",
    "\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.ones(1,4,3,3) #(데이터개수,channel,height,width)\n",
    "feature_map = layer(input_data)\n",
    "print(feature_map.shape)\n",
    "\n",
    "#[1:데이터개수, 2:out_channels, 1:height,1:width]\n",
    "#출력하는 것을 통해, 사이즈가 줄어듬을 볼 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파라미터 weight를 조회할 수 있다.\n",
    "weight=layer.weight  #conv2d의 weight를 조회한다. =>filter를 조회.\n",
    "weight.shape\n",
    "#[2:filter의 개수, 4:필터의 채널 개수, 3:필터 height, 3:필터 width]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1525, 0.1640], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파라미터 bias(필터 당 하나씩 붙어주는 값)\n",
    "\n",
    "bias = layer.bias\n",
    "print(bias.shape)#2가 나오는데, 이는 필터의 개수와 같다.\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 3]), torch.Size([4, 3, 3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#첫번째 필터 계산\n",
    "\n",
    "input_data[0].shape, weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2992, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#filter를 통해 계산하는 과정. 첫번째 필터를 계산한다.\n",
    "#여기서 핵심은 채널별로 계산을 한다는 것이다.\n",
    "\n",
    "ch1=torch.sum(input_data[0,0] * weight[0,0]) #[0:첫번째 필터, 0:첫번째 채널]\n",
    "ch2=torch.sum(input_data[0,1] * weight[0,1]) #[0:첫번째 필터, 1:두번째 채널]\n",
    "ch3=torch.sum(input_data[0,2] * weight[0,2]) #[0:첫번째 필터, 2:세번째 채널]\n",
    "ch4=torch.sum(input_data[0,3] * weight[0,3]) #[0:첫번째 필터, 3:네번째 채널]\n",
    "\n",
    "#convolution result of the channel을 계산.\n",
    "result = ch1+ch2+ch3+ch4+bias[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4674, 0.0888, 0.8674, 0.9868],\n",
       "         [0.6524, 0.7556, 0.4409, 0.2806],\n",
       "         [0.3109, 0.8473, 0.7244, 0.0778],\n",
       "         [0.2847, 0.2395, 0.5993, 0.3350]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_layer = nn.MaxPool2d(kernel_size=2, #최대값을 추출할 영역 크기\n",
    "                       #영역 중에서 2*2 영역을 잡아서, 그 중에서의 최대값을 찾아 내는 것이다.\n",
    "                       stride = 2, #이동 하는 size를 지정해준다. \n",
    "                       #보통은 kernel_size와 stride를 같은 값을 지정해서 겹치지 않도록 한다.\n",
    "                       #이 둘이 겹치면 대표값의 대표성이 사라진다.\n",
    "                       \n",
    "                       \n",
    "                      )\n",
    "\n",
    "\n",
    "input_data2 = torch.rand(1,4,4)\n",
    "input_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = p_layer(input_data2)\n",
    "result2.shape\n",
    "#사이즈를 보면 절반으로 줄어들었다. \n",
    "\n",
    "\n",
    "\n",
    "#위의 출력값을 4등분해서, 각 등분의 영역에서 가장 큰 값을 추출해서 나타낸 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드를 작성하기 전에, 필수사항들을 import 한다.\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from module.data import load_mnist_dataset, load_fashion_mnist_dataset\n",
    "from module.train import fit\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter\n",
    "\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_mnist_dataset(\"datasets\",BATCH_SIZE,True) #저장경로,batch크기,Trainset 여부\n",
    "test_loader = load_mnist_dataset(\"datasets\",BATCH_SIZE,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: datasets\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터를 잘 가져왔나 확인한다\n",
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN ->Convolution Layer: filter개수(out_channels로 설정) 뒤로 갈수록 크게 잡는다.\n",
    "#Max Pooling Layer를 이용해서 출력 결과의 size는 줄여나간다.(보통 2배씩 줄인다.)\n",
    "\n",
    "\n",
    "#conv block을 만드는 패턴\n",
    "#1. conv + relu + maxpooling\n",
    "#2. Conv + BatchNorm + ReLU + MaxPooling\n",
    "##3. Conv + BatchNorm + ReLU + Dropout + MaxPooling\n",
    "\n",
    "\n",
    "class MNISTCNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = nn.Sequential(\n",
    "        #Conv2d():3*3 필터,stride와 padding이 1로 같다. 이는 입력 size와 출력 size가 같다는 것을 의미한다.\n",
    "        nn.Conv2d(1,32,kernel_size=3, stride=1,padding=1),\n",
    "        nn.BatchNorm2d(32), #channel을 기준을 정규화한다. -> 입력 channel수를 지정한다.\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(p=0.3),\n",
    "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        #kernel_size와 stride가 같은 겨우에는 stride를 생략할수 있다.\n",
    "        #MaxPool2d() 에서도 padding을 지정할 수 있다.\n",
    "        \n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "        nn.Conv2d(32,64,kernel_size=3,padding=\"same\"), #더 늘려나간다.\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2)    \n",
    "        \n",
    "        \n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.b3 = nn.Sequential(\n",
    "        nn.Conv2d(64,128,kernel_size=3,padding=\"same\"),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(p=0.3),\n",
    "        nn.MaxPool2d(kernel_size=2,padding=1) #입력: 7*7이고 2등분으로 줄이면 3.5이다.\n",
    "            #이를 살리기 위해 padding을 지정한다.\n",
    "        \n",
    "        )\n",
    "        \n",
    "        \n",
    "        #결과 출력레이터 =>Linear() 사용.\n",
    "        self.output_block = nn.Sequential(\n",
    "        #MaxPool2d(), #출력결과를 입력으로 받는다. =>4차원이다.\n",
    "         #3차원 => 1차원\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=128*4*4,out_features=512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(512,10) #out=>클래스 개수\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        out = self.b1(X)\n",
    "        out = self.b2(out)\n",
    "        out = self.b3(out)\n",
    "        out = self.output_block(out) #이를 통해 결국 10개의 값을 출력받는다.\n",
    "        #이름이 output_block인 것을 숙지하자.\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MNISTCNNModel                            [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 28, 28]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 28, 28]           --\n",
       "│    └─Dropout2d: 2-4                    [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 32, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 64, 7, 7]             --\n",
       "│    └─Conv2d: 2-6                       [1, 64, 14, 14]           18,496\n",
       "│    └─BatchNorm2d: 2-7                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-8                         [1, 64, 14, 14]           --\n",
       "│    └─MaxPool2d: 2-9                    [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-3                        [1, 128, 4, 4]            --\n",
       "│    └─Conv2d: 2-10                      [1, 128, 7, 7]            73,856\n",
       "│    └─BatchNorm2d: 2-11                 [1, 128, 7, 7]            256\n",
       "│    └─ReLU: 2-12                        [1, 128, 7, 7]            --\n",
       "│    └─Dropout2d: 2-13                   [1, 128, 7, 7]            --\n",
       "│    └─MaxPool2d: 2-14                   [1, 128, 4, 4]            --\n",
       "├─Sequential: 1-4                        [1, 10]                   --\n",
       "│    └─Flatten: 2-15                     [1, 2048]                 --\n",
       "│    └─Linear: 2-16                      [1, 512]                  1,049,088\n",
       "│    └─ReLU: 2-17                        [1, 512]                  --\n",
       "│    └─Dropout: 2-18                     [1, 512]                  --\n",
       "│    └─Linear: 2-19                      [1, 10]                   5,130\n",
       "==========================================================================================\n",
       "Total params: 1,147,338\n",
       "Trainable params: 1,147,338\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.55\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.71\n",
       "Params size (MB): 4.59\n",
       "Estimated Total Size (MB): 5.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary를 통해 간략한 정보를 보도록 하자.\n",
    "\n",
    "model = MNISTCNNModel()\n",
    "summary(model,(1,1,28,28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1] - Train loss: 0.05175 Train Accucracy: 0.98370 || Validation Loss: 0.04545 Validation Accuracy: 0.98500\n",
      "====================================================================================================\n",
      "78.43084287643433 초\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "\n",
    "result = fit(train_loader,test_loader,model,loss_fn,optimizer,N_EPOCH,\n",
    "             save_best_model=False,early_stopping=True,device=device,mode=\"multi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2ARCyjDW66NR",
    "6bAN1wPG66NS",
    "shNUg6al66NV",
    "7xgQxAU666NZ"
   ],
   "name": "07_CNN_MNIST분류, 모델저장.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
