{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28078254-f3d9-4917-868a-6c9e684f385f",
   "metadata": {},
   "source": [
    "# Sequential 데이터란\n",
    "\n",
    "- 데이터의 **순서 정보가 중요한 데이터셋으로** 순서가 달라질 경우 의미가 바뀌거나 손상되는 데이터를 말한다.\n",
    "- 예\n",
    "    - 자연어 텍스트\n",
    "    - 일정한 주기로 샘플링된 영상, 음성\n",
    "    - 시계열(time series) 데이터\n",
    "- Time series\n",
    "    - Sequential 데이터중 데이터는 순서에 더해 해당 **데이터가 발생한 시점 정보가 중요한 데이터셋을** 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67f648-4c58-4f51-af08-785ce7e85937",
   "metadata": {},
   "source": [
    "# RNN (Recurrent Neural Network) 구조\n",
    "\n",
    "## 개요\n",
    "- RNN은 Recurrent Layer을 사용하는 딥러닝 모델을 말한다.\n",
    "    - Feature 추출기로 Recurrent layer를 사용한다.\n",
    "- Recurrent Layer는 sequential 데이터 처리에 좋은 성능을 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e30211-1b9b-42cb-9625-1fbb789fc6aa",
   "metadata": {},
   "source": [
    "## Recurrent Layer 구조\n",
    "- Sequential 데이터 순서에 맞춰 처리하는 것이 중요하다. 그러나 DNN, CNN은 순서를 고려하지 않고 특성 추출과 추론을 한다.\n",
    "- RNN은 순서대 입력되는 데이터를 반복 처리하는  **Recurrent Layer**를 이용해 **Feature vector를 추출하고** 그 Feature vector를 Estimator Layer에 전달해 추론한다.\n",
    "\n",
    "### 메모리 시스템(Memory system)\n",
    "- Sequential를 처리하는데 중요한 것은 **기억(memory)** 이다.\n",
    "    - 단순이 순서대로 처리하는 것 뿐만 아니라 **이전 단계의 처리결과를 기억하고 그것을 현재 단계 처리에 사용한다.**\n",
    "\n",
    "> Sequential 데이터 처리에서 순서대로 처리할 때 각각의 단계를 **time step** 이라고 한다.\n",
    " \n",
    "![memory system](figures/rnn/01_memory_system.png)\n",
    "\n",
    "- 예를 들어 4일간의 주가 변화로 5일째 주가를 예측하려면 입력받은 4일간의 주가를 순서를 기억하고 있어야 한다.\n",
    "- Fully Connected Layer나 Convolution Layer의 출력은 이전 Data에 대한 처리와 상관없이 현재 데이터를 기준으로만 특성을 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a4b01-660e-46b7-85ff-ea513a4e3bb4",
   "metadata": {},
   "source": [
    "### Simple RNN 구조\n",
    "![rnn arch](figures/rnn/02_simplernn.png)\n",
    "\n",
    "\n",
    "![rnn_arch2](figures/rnn/03_simplernn_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca14607",
   "metadata": {},
   "outputs": [],
   "source": [
    "wx:\"x의 가중치\", wh:\"h의 가중치\",b = w1,w2,w3\n",
    "        \n",
    "def RNN(X:\"현재데이터\",h:\"이전처리\"):\n",
    "    return tanh(X@wx+h@wh+b)\n",
    "\n",
    "hidden = 0\n",
    "for i in range(10):\n",
    "    #range가 제공하는 값이 현재순서의 값\n",
    "    hidden = RNN(i,hidden)\n",
    "    #이렇게 되면, hidden에 그 전에 처리한 값이 들어가게 된다.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fefa278-785b-4dcb-aaa7-622a6be6c162",
   "metadata": {},
   "source": [
    "- Recurrent Layer의 Layer는 Linear layer 구조에 재귀 순환(반복)의 개념이 들어간 것으로 이해할 수 있다.\n",
    "- Layer의 한 step은 입력으로 현재 시점(time step)의 입력 데이터($X_{t}$)와 이전 시점의 처리결과($h_{t-1}$)를 같이 받는다.  (t: time step)\n",
    "- $X_{t}$와 $h_{t-1}$ 에 각각의 weight($W_{xh}\\,, W_{hh}$)를 이용해 가중합을 구하고 그 둘의 합계를 activation(tanh) 함수에 넣어 처리한 결과가 그 단계의 출력값이된다.\n",
    "    - $X_{t}$와 $h_{t-1}$ 는 각각 다른  weight($W_{xh}$, $W_{hh}$) 를 내적한다.\n",
    "- 이전 단계의  출력값은 다시 다음 step의 hidden state로 전달된다.\n",
    "- **hidden state**\n",
    "    - 이전 step의 처리결과로 현재 step에 입력되는 값을 말한다.\n",
    "    - **메모리 시스템의 메모리(기억)** 에 해당한다.\n",
    "    - 매 타임스텝별로 사용되는 가중치 $W_{xh}$, $W_{hh}$ 는 동일한 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe180f6-3fe2-4b25-b629-c4f55ad4113e",
   "metadata": {},
   "source": [
    "## 문제 유형별 RNN 구조\n",
    "\n",
    "|유형|구조1|구조2|구현서비스(App)|\n",
    "|:-|:-|:-:|-:|\n",
    "|**Many to One**|입력: Sequence Vector(여러개의 Vector)<br>출력: 1개 Vector|![mto](figures/rnn/04_many_to_one.png)|Text classification(감성 분석)|\n",
    "|**One to Many**|입력: 1개 Vector<br>출력: Sequence Vector|![otm](figures/rnn/04_one_to_many.png)|Image captioning<br>문장생성|\n",
    "|**Many to Many**|입력: Sequence Vector<br>출력: Sequence Vector|![mtm1](figures/rnn/04_many_to_many.png)|개체명인식<br>품사태깅|\n",
    "|**Seq2Seq**|many to one과 one to many 를 연결한 구조.<br>Encoder, Decoder 구조|![seq2seq](figures/rnn/04_seq2seq.png)|Machine Translation<br>Chatbot|\n",
    "\n",
    "\n",
    "- **텍스트 분류(Text classification)**\n",
    "   - 입력받은 문장을 분류하는 문제로 대표적으로 감성분석(sementic analysis)가 있다.\n",
    "   - 감성분석: 입력받은 텍스트가 긍정적인지 부적적인 글인지 분류하는 문제\n",
    "- **Image captioning**\n",
    "   - 입력받은 이미지를 설명하는 문장을 생성하는 문제.\n",
    "- **개체명인식(Named Entity Recognition)**\n",
    "   - 문장의 각 단어가 어떤 종류(의미) 인지를 찾는 문제\n",
    "   - 미국에 사는 톰은 스무살입니다. ==> 미국: 위치, 톰: 이름, 스므살: 나이\n",
    "- **품사태깅(Pos tagging)**\n",
    "   - 문장의 각 토큰의 품사를 찾는 문제\n",
    "   - 미국에 사는 톰은 스무살입니다. ==> 미국: 대명사, 예: 조사,  톰: 대명사, 은: 조사, 스무: 명사, 살: 명사, 이다: 동사\n",
    "- **Chatbot**\n",
    "   - 입력받은 문장에 대한 답을 하는 시스템.\n",
    "   - encoder는 질문을 받아 처리하고 decoder는 답변을 생성한다.\n",
    "- **Machine translation**\n",
    "   - 번역 시스템\n",
    "   - encoder는 번역 대상문장을 입력받아 처리하고 decoder는 번역 문장을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c212f68d-b27c-4725-901c-7e98a422ef8d",
   "metadata": {},
   "source": [
    "## Bidirectional RNN\n",
    "- 같은 정보를 정방향과 역방향 두 방향으로 주입해 정확도를 높인다.\n",
    "- Non-Auto Regressive 모델의 경우 bidirectional RNN 사용이 권장된다.\n",
    "\n",
    "> - **Auto Regressive 모델**\n",
    ">     - 이전 time step에 대한 출력결과를 다음 time step의 입력으로 사용하는 구조.\n",
    ">         - Text 생성 모델이 대표적인 Auto Regressive 모델이다.\n",
    ">     - 이전 출력의 결과에 의존하기 때문에 bidirectional RNN을 사용할 수 없다.\n",
    ">     - Non Auto Regressive 모델은 현재의 상태가 앞/뒤 상태에 따라 정해지는 경우로 앞/뒤의 상태를 모두 참조할 경우 성능이 올라가는 경우를 말한다. 이때 bidirectional RNN 의 사용이 권장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a16bb-d113-4d08-814a-6065b57f96c2",
   "metadata": {},
   "source": [
    "![bidirectional](figures/rnn/08_bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb53f18-66db-474d-acdf-2963c6837916",
   "metadata": {},
   "source": [
    "## Stacking(Multi Layer) RNN\n",
    "\n",
    "- Recurrent Layer를 쌓아 모델의 용량을 늘려 표현능력(Represenational capacity)를 증가시킨다.\n",
    "- 여러층을 쌓은 경우 먼저 쌓은 layer의 모든 time step별 출력이 다음 Layer의 입력 데이터로 사용된다.\n",
    "- Layer을 쌓으면 표현능력은 증가하는 대신 계산 비용이 많이들고 **과대적합(Overfitting)이** 발생할 수 있다.\n",
    "    - 과대적합을 막기 위해 드롭아웃 레이어를 추가할 수있다.\n",
    "    - Recurrent Layer에서 Dropout layer는 매 time step 마다 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbc98e-5794-41d4-9f86-4339790557fd",
   "metadata": {},
   "source": [
    "![stacking rnn](figures/rnn/08_multi_layer_rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aeefa1-2cdf-4535-9227-c7a125fd8883",
   "metadata": {},
   "source": [
    "## Pytorch RNN Layer\n",
    "\n",
    "- [nn.RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
    "    - **파라미터**\n",
    "        - input_size: 입력 데이터의 shape\n",
    "        - hidden_size: Layer의 Hidden size\n",
    "        - num_layers: 몇층으로 Layer을 쌓을지 개수\n",
    "        - nonlinearity: 활성함수로 'tanh' (Default), 'relu' 둘 중 하나 지정.\n",
    "        - batch_first: True - (batch, seqence len, ..) False - (sequence len, batch, ..). Default: False\n",
    "        - dropout: Dropout rate 비율\n",
    "        - bidirectional:  양방향 적용 여부. Default: False\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966f316-99c6-408d-8b34-63f83eefbf61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "  \n",
    "### RNN Layer의 input / output tensor 의 shape\n",
    "\n",
    "### 추론시 Input\n",
    "- Input_Data, Hidden_state\n",
    "- Input_data의 shape\n",
    "    - (Sequence_legnth, batch_size, feature_shape)\n",
    "        - pytorch 는 입력으로 batch 보다 sequence length가 먼저 온다.\n",
    "        - batch_first=True 로 설정하면 (**batch_size**, seq_len, feature_shape) 순이 된다.\n",
    "        - ex)  주가 데이터\n",
    "            - feature: 시가, 종가, 최고가, 최저가\n",
    "            - sequence: 100일치\n",
    "            - batch size: 30\n",
    "            - (100, 30, 4)\n",
    "    ![input tensor shape](figures/rnn/07_input_shape.png)\n",
    "- Hidden_state의 shape\n",
    "    - 시작(초기) hidden state로 입력하지 않으면 0이 들어간다.\n",
    "    - shape은 아래 hidden state 설명 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04175c-65d5-43dd-b3dc-5646d390b47a",
   "metadata": {},
   "source": [
    "### Output\n",
    "- (output_data, hidden_state)\n",
    "- output_data과 hidden state를 tuple로 묶어서 반환한다.\n",
    "- Output_data:\n",
    "    - 매 time step의 출력결과\n",
    "    - Many to Many일 경우 이것을 출력결과로 사용한다.\n",
    "- hidden_state\n",
    "    - 마지막 time step의 출력결과\n",
    "    - Many to one의 경우 이것을 출력결과로 사용한다.\n",
    "  \n",
    "#### Output shape\n",
    "- **(Sequence length, batch_size, hidden_size * D)**\n",
    "    - D: 2 if bidirectional else 1\n",
    "    - batch_first=True 로 설정하면 (**batch_size**, seq_len, feature_shape) 순이 된다.\n",
    "    - ex)\n",
    "        - RNN Layer의 hidden size가 256 인 경우. (sequence length: 100, batch size: 30, bidirection=False)\n",
    "        -  (100, 30, 256)\n",
    "![hidden state shape](figures/rnn/07_hidden_state_shape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e97aff-48db-4083-b6fb-10651ac518ba",
   "metadata": {},
   "source": [
    "#### Hidden state\n",
    "- 마지막 time step의 출력결과\n",
    "    - **(D * layer수, batch_size, hidden_size)**\n",
    "    -  D: 2 if bidirectional else 1\n",
    "    -  layer수: multi layer일 경우 layer stack 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02616da3-d879-4a11-b63e-804ede8241b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74f2a5-d789-439e-a0d7-fd73c3175c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9f640-e5cb-4439-9e34-40d7cb702a3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe880b3-a1ca-4158-ad64-0856b90bea78",
   "metadata": {},
   "source": [
    "# RNN의 Back Propagation \n",
    "- BPTT(Back Propagation Through Time) 이라고 한다.\n",
    "- RNN이 sequential하기 때문에 발생하는 hidden state를 따라 역행하면서 전파되는 gradient의 계산 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f75381-a29a-4e97-93ff-0bea964a798f",
   "metadata": {},
   "source": [
    "## RNN(Simple RNN)의 문제 \n",
    "- 입력 데이터의 sequence가 길수록 Gradient Vanishing으로 초기 Sequence에 대한 학습이 안되는 문제가 RNN의 고질적인 문제이다.\n",
    "    - RNN은 activation 함수로 tanh()를 사용한다. tanh()의 gradient는 0 ~ 1 사이의 실수가 나온다. 그래서 sequence가 길어지면 초기 time step의 값에 대한 weight가 업데이트가 되지 않게 된다.  \n",
    "    - 초기 Sequence에 대해 학습이 안되어서 **기억력 소실문제** 라고 한다.\n",
    "      \n",
    "![BPTT](figures/rnn/09_bptt.png)\n",
    "\n",
    "- 이런 Simple RNN의 문제 모델 구조로 해결한 모델이 **LSTM이나 GRU** 모델이다. Sequence 데이터 처리 모델로 이 둘을 주로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2ca22-3cea-4d5f-b9b1-33fb14998d43",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "## 개요\n",
    "\n",
    "![lstm](figures/rnn/09_lstm_layer.png)\n",
    "\n",
    "- **Cell State**\n",
    "    - Long term memory 로 전체 step에 대한 누적 기억값\n",
    "- **Hidden State**\n",
    "    - Short term memory 로 이전 sequence 에 대한 기억값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a87ce-dd27-42ec-90f6-80d64b20f686",
   "metadata": {},
   "source": [
    "## LSTM  Gate\n",
    "- Gate: sigmoid 를 이용해 값의 얼마를 적용할지 정한다. 이것을 문이 열리고 닫히는 의미로 Gate라고 한다.\n",
    "- 다음 3개 Gate로 구성\n",
    "    -  Forget gate\n",
    "    -  Input gate\n",
    "    -  Output gate\n",
    "-  각 Gate는 hidden state와 Input data에 곱하는 Weight들을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7827d9d-bc6f-4e8e-ae6f-79f9f83ceaa0",
   "metadata": {},
   "source": [
    "![lstm](figures/rnn/10_lstm_layer_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52849-2742-48a8-91ba-b73ecf2d1a3b",
   "metadata": {},
   "source": [
    "### Forget gate\n",
    "![forget gate](figures/rnn/11_forget_gate.jpg)\n",
    "\n",
    "- 이전 time step의 hidden state와 현재 time step의 입력데이터를 기준으로 장기 기억인 cell state에서 얼마나 잊을 지 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511772d5-da37-4504-adde-143906285e20",
   "metadata": {},
   "source": [
    "### Input Gate\n",
    "\n",
    "![input gate](figures/rnn/12_input_gate.jpg)\n",
    "- 이전 time step의 hidden state와 현재 time step의 입력데이터를 cell state에서 얼마나 반영할 지 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69ac70-0a6e-4926-8971-9297f8ceab9b",
   "metadata": {},
   "source": [
    "### Cell State update\n",
    "\n",
    "![update](figures/rnn/13_cell_state_update.jpg)\n",
    "- cell state는 forget gate의 결과를 곱해서 얼마나 잊을지 결정하고 input gate의 결과를 더해서 현재 입력에 대한 정보를 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ac17d-3a9b-42c2-b7ec-4eac217cbb60",
   "metadata": {},
   "source": [
    "### Output Gate\n",
    "![output gate](figures/rnn/14_output_gate.jpg)\n",
    "- 이전 time step의 hidden state와 현재 time step의 입력데이터, 현재 step의 입력이 반영된 Cell state를 이용해 출력 결과를 계산한다.\n",
    "-  **Output gate의 계산 결과는 다음 step에 hidden state(단기기억)로 전달된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c487433-a5bd-4754-aecc-587147430e05",
   "metadata": {},
   "source": [
    "<Image 참조> https://www.pluralsight.com/guides/introduction-to-lstm-units-in-rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3387a-4990-45e7-81be-ce555a7ea692",
   "metadata": {},
   "source": [
    "## Pytorch LSTM layer\n",
    "\n",
    "- [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "    - **파라미터**\n",
    "        - input_size: 입력 데이터의 shape\n",
    "        - hidden_size: Layer의 Hidden size\n",
    "        - num_layers: 몇층으로 Layer을 쌓을지 개수\n",
    "        - batch_first: True - (batch, seqence len, ..) False - (sequence len, batch, ..). Default: False\n",
    "        - dropout: Dropout rate 비율\n",
    "        - bidirectional:  양방향 적용 여부. Default: False\n",
    "     \n",
    "### 추론시 input / output tensor\n",
    "### 추론시 Input\n",
    "- Input_data, (Hidden_state, Cell_state)\n",
    "- Input_data의 shape\n",
    "    - **(sequence_length, batch_size, input_feature_shape)**\n",
    "- (Hidden_state, Cell_state)는 생략시 0 입력된다.\n",
    "    - Hidden_state의 shape\n",
    "        - **(D * layer수, batch_size, hidden_size)**\n",
    "        - D: 2 if bidirectional else 1\n",
    "    - Cell_state의 shape\n",
    "        - **(D * layer수, batch_size, hidden_size)**\n",
    "        - D: 2 if bidirectional else 1\n",
    "### Output\n",
    "- Output_data, (Hidden_state, Cell_state)\n",
    "  \n",
    "#### Output_data의 shape\n",
    "- 모든 timestep의 출력결과를 묶어서 반환\n",
    "- **(sequence length, batch_size, D * hidden_size)**\n",
    "#### Hidden_state의 shape\n",
    "- 마지막 timestep의 출력결과\n",
    "- **(D * layer수, batch_size, hidden_size)**\n",
    "- D: 2 if bidirectional else 1\n",
    "#### Cell_state의 shape\n",
    "- cell state(장기기억) 값\n",
    "- **(D * layer수, batch_size, hidden_size)**\n",
    "- D: 2 if bidirectional else 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9c4e11-9932-4e9b-a0bc-13733a4891f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "input_data = torch.randn(100,30,6) #[seql len, batch size, feature 수]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48123082-fc82-40bb-b514-95131fbc4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===LSTM: hidden_size(unit수)=200, num_layers=1, bidirectional=False===\n",
      "output: torch.Size([100, 30, 200]), hidden: torch.Size([1, 30, 200]), cell: torch.Size([1, 30, 200])\n"
     ]
    }
   ],
   "source": [
    "#LSTM 모델을 새롭게 정의한다.\n",
    "lstm1 = nn.LSTM(input_size=6, #feature수\n",
    "               hidden_size=200,num_layers=1)\n",
    "\n",
    "print(\"===LSTM: hidden_size(unit수)=200, num_layers=1, bidirectional=False===\")\n",
    "\n",
    "output1, (hidden1,cell1) = lstm1(input_data)\n",
    "type(output),type(hidden)\n",
    "#output: 모든 타입 step 출력\n",
    "#hidden: 바로 전 step 처리 결과(모든 과정을 다 거쳐서 나온 결과)\n",
    "#cell_state: 이전 모든 step에 대한 처리 결과이다.(이전 step에서만 처리된 결과)\n",
    "\n",
    "\n",
    "#결과들을 출력한다.\n",
    "print(f\"output: {output1.shape}, hidden: {hidden1.shape}, cell: {cell1.shape}\")\n",
    "\n",
    "#output: [100:seq개수, 30: batch, 200:hidden크기(유닛수)]\n",
    "#hidden: [layer수 * 양방향여부, batch, hidden 개수]\n",
    "#cell: [layer수 * 양방향여부, batch, hidden 개수]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fe408a-4828-4c56-9ba4-321fa8514b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===LSTM: hidden_size(unit수)=200, num_layers=1, bidirectional=False===\n",
      "output: torch.Size([100, 30, 400]), hidden: torch.Size([2, 30, 200]), cell: torch.Size([2, 30, 200])\n"
     ]
    }
   ],
   "source": [
    "#bidircetion을 추가한다.\n",
    "#bidircetion을 추가함에 따라 출력값이 어떻게 바뀌는지 파악하자.\n",
    "lstm2 = nn.LSTM(input_size=6, #feature수\n",
    "               hidden_size=200,num_layers=1,bidirectional=True)\n",
    "\n",
    "print(\"===LSTM: hidden_size(unit수)=200, num_layers=1, bidirectional=False===\")\n",
    "\n",
    "output2, (hidden2,cell2) = lstm2(input_data)\n",
    "type(output),type(hidden)\n",
    "#output: 모든 타입 step 출력\n",
    "#hidden: 바로 전 step 처리 결과(모든 과정을 다 거쳐서 나온 결과)\n",
    "#cell_state: 이전 모든 step에 대한 처리 결과이다.(이전 step에서만 처리된 결과)\n",
    "\n",
    "\n",
    "#결과들을 출력한다.\n",
    "print(f\"output: {output2.shape}, hidden: {hidden2.shape}, cell: {cell2.shape}\")\n",
    "\n",
    "#output: [100:seq개수, 30: batch, 400:hidden크기(유닛수)]----양방향이기 때문에 400개이다.\n",
    "#hidden: [layer수(1) * 양방향여부(2), batch, hidden 개수]\n",
    "#cell: [layer수(1) * 양방향여부(2), batch, hidden 개수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731e049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4a16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
